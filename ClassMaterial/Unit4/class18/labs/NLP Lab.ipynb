{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Lab:  NLP\n",
    "\n",
    "Welcome to tonight's lab!  Tonight we're going to build a neural network to analyze text data.  We'll be using the IMDB dataset to train our model on movie reviews to predict whether or not they convery a positive or negative sentiment.  \n",
    "\n",
    "During the lab we'll use Keras to build a 3 layer neural network with word embeddings and densely connected outer layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1:  Read in the IMDB dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Process Your Data\n",
    "\n",
    "Take the following steps:\n",
    "\n",
    " - For the target variable, encode `positive` and `negative` to `1` and `0`\n",
    " - Create a training and a test set.  Since there's no order to this dataset, randomly shuffling is fine.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3:  Tokenize Your Word Documents\n",
    "\n",
    "\n",
    "**3a:** Import the necessary portions of the keras library:\n",
    "\n",
    "To do this, you'll need the following parts of Keras:\n",
    "\n",
    " - `keras.preprocessing.text.Tokenizer`\n",
    " - `keras.preprocessing.sequences.pad_sequences`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3b:** Use the `Tokenizer` to process your text data.\n",
    "\n",
    "Use the following methods to appropriately process your training and test data:\n",
    "\n",
    " - `fit_on_texts`\n",
    " - `texts_to_sequences`\n",
    " \n",
    "**Note:** Use a maximum vocabulary size of 10000 words when you initialize the Tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3c:** Equalize the length of each review\n",
    "\n",
    "You have some discretion on this step, and you might want to play around with different variations of this if you have additional time, but for now set each document to 150 characters long, using the `pad_sequences` method in Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3d:** Double check your data\n",
    "\n",
    "At this point, it's probably a good idea to make sure you understand what you just did, and how your data is setup.  \n",
    "\n",
    "Try and do the following, and make sure you can connect the dots:\n",
    "\n",
    " - Check the `word_index` of your tokenizer\n",
    " - Check the data type of your new training and test sets -- what are they?\n",
    " - What does each document consist of?  What about documents that are less than 150 words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4:  Initialize Your Keras Model\n",
    "\n",
    "**What you'll need:** The `Sequential` method from Keras.  This is how you connect different neural network layers together\n",
    "\n",
    "**How it will be setup:** Make it have the following layers:\n",
    "\n",
    " - A word embedding -- make sure the dimensions are as follows:\n",
    "  - `num_words`, `num_weights`, `document_length`\n",
    " - A Dense layer with your choice of neurons and activation function\n",
    " - A Dense layer with **1** neuron and your choice of activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Compile Your Neural Network\n",
    "\n",
    "Unlike scikit-learn, you have to specify a few additional parameters to fit your neural network.  \n",
    "\n",
    "They are as follows:\n",
    "\n",
    " - `optimizer`: this is the technique you use to update your weights.  The standard method is **Stochastic Gradient Descent**, which can be entered as `sgd`.  The more modern method is **ADAM**, which can be entered as `adam`.  Take your pick of which one to choose.\n",
    " - `loss`: this is the loss function you use to **train** your weights.  Since we are doing binary classification then the correct one to use is **binary cross_entropy**\n",
    " - `metrics`: this is how you **score** your model.  This is optional.  But accuracy is always a solid choice here.  This can be entered as `acc`, passed in through a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6:  Fit Your Model\n",
    "\n",
    "Now you can go ahead and call fit.  A few arguments to keep in mind:  \n",
    "\n",
    " - `validation_split`: how much of your training data to use for test data.  This takes a decimal less than 1 as an argument.\n",
    " - `epochs`:  how many rounds of training to do to update your weights\n",
    " \n",
    "You can choose the appropriate values for these as you see fit.\n",
    "\n",
    "**Hint:** Keras does not takes pandas as input, so you'll need to make sure it's converted to numpy first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 7: Diagnostics\n",
    "\n",
    "Now is a good time to take a look at your results.  \n",
    "\n",
    "By the end of your training run, were you overfitting or underfitting?  Did it look like your results were converging towards a stable answer, or was there more training that needed to be done?  \n",
    "\n",
    "A reasonably good performance on this dataset is a validation accuracy of about 86-89%. \n",
    "\n",
    "If you hit this level, then you should be fine, if you didn't, then you might try changing a few things, including:\n",
    "\n",
    " - Adding more neurons to give your model greater potential for accuracy\n",
    " - Trying a different optimizer (this probably won't help much, but it never hurts)\n",
    " - Using a different set of activation functions\n",
    " \n",
    "Try and fiddle around with a few parameters to see if you can get some measurable improvement.  \n",
    "\n",
    "**Bonus:** The Deep Learning antidote to overfitting is a special type of layeer called **dropout**:  it allows a portion of the data that will be randomly removed between one layer and the next, to prevent a neural network from randomly memorizing spurious connections within your data.\n",
    "\n",
    "It's very easy to setup:\n",
    "\n",
    "`keras.model.layers.Dropout(0.3)`, where `0.3` is the amount of data to randomly remove.  You can add it just like any other layer in your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
